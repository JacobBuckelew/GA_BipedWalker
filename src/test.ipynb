{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def glorot_uniform(n_inputs,n_outputs,multiplier=1.0):\n",
    "    ''' Glorot uniform initialization '''\n",
    "    glorot = multiplier*np.sqrt(6.0/(n_inputs+n_outputs))\n",
    "    return np.random.uniform(-glorot,glorot,size=(n_inputs,n_outputs))\n",
    "\n",
    "def softmax(scores,temp=5.0):\n",
    "    ''' transforms scores to probabilites '''\n",
    "    exp = np.exp(np.array(scores)/temp)\n",
    "    return exp/exp.sum()\n",
    "\n",
    "class Agent(object):\n",
    "    ''' A Neural Network '''\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, mutate_rate=.05, init_multiplier=1.0):\n",
    "        ''' Create agent's brain '''\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_outputs = n_outputs\n",
    "        self.mutate_rate = mutate_rate\n",
    "        self.init_multiplier = init_multiplier\n",
    "        self.network = {'Layer 1' : glorot_uniform(n_inputs, n_hidden,init_multiplier),\n",
    "                        'Bias 1'  : np.zeros((1,n_hidden)),\n",
    "                        'Layer 2' : glorot_uniform(n_hidden, n_outputs,init_multiplier),\n",
    "                        'Bias 2'  : np.zeros((1,n_outputs))}\n",
    "                        \n",
    "    def act(self, state):\n",
    "        ''' Use the network to decide on an action '''        \n",
    "        if(state.shape[0] != 1):\n",
    "            state = state.reshape(1,-1)\n",
    "        net = self.network\n",
    "        layer_one = np.tanh(np.matmul(state,net['Layer 1']) + net['Bias 1'])\n",
    "        layer_two = np.tanh(np.matmul(layer_one, net['Layer 2']) + net['Bias 2'])\n",
    "        return layer_two[0]\n",
    "    \n",
    "    def __add__(self, another):\n",
    "        ''' overloads the + operator for breeding '''\n",
    "        child = Agent(self.n_inputs, self.n_hidden, self.n_outputs, self.mutate_rate, self.init_multiplier)\n",
    "        for key in child.network:\n",
    "            n_inputs,n_outputs = child.network[key].shape\n",
    "            mask = np.random.choice([0,1],size=child.network[key].shape,p=[.5,.5])\n",
    "            random = glorot_uniform(mask.shape[0],mask.shape[1])\n",
    "            child.network[key] = np.where(mask==1,self.network[key],another.network[key])\n",
    "            mask = np.random.choice([0,1],size=child.network[key].shape,p=[1-self.mutate_rate,self.mutate_rate])\n",
    "            child.network[key] = np.where(mask==1,child.network[key]+random,child.network[key])\n",
    "        return child\n",
    "    \n",
    "def run_trial(env,agent,verbose=False):\n",
    "    ''' an agent performs 3 episodes of the env '''\n",
    "    totals = []\n",
    "    for _ in range(3):\n",
    "        state = env.reset()\n",
    "        if verbose: env.render()\n",
    "        total = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            state, reward, done, _ = env.step(agent.act(state))\n",
    "            if verbose: env.render()\n",
    "            total += reward\n",
    "        totals.append(total)\n",
    "    return sum(totals)/3.0\n",
    "\n",
    "def next_generation(env,population,scores,temperature):\n",
    "    ''' breeds a new generation of agents '''\n",
    "    scores, population =  zip(*sorted(zip(scores,population),reverse=True))\n",
    "    children = list(population[:int(len(population)/4)])\n",
    "    parents = list(np.random.choice(population,size=2*(len(population)-len(children)),p=softmax(scores,temperature)))\n",
    "    children = children + [parents[i]+parents[i+1] for i in range(0,len(parents)-1,2)]\n",
    "    scores = [run_trial(env,agent) for agent in children]\n",
    "\n",
    "    return children,scores\n",
    "\n",
    "def main():\n",
    "    ''' main function '''\n",
    "    # Setup environment\n",
    "    env = gym.make('BipedalWalker-v2')\n",
    "    env.seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # network params\n",
    "    n_inputs = env.observation_space.shape[0]\n",
    "    n_actions = env.action_space.shape[0]\n",
    "    n_hidden = 512\n",
    "    multiplier = 5\n",
    "    \n",
    "    # Population params\n",
    "    pop_size = 64\n",
    "    mutate_rate = .1\n",
    "    softmax_temp = 5.0\n",
    "    \n",
    "    # Training\n",
    "    n_generations = 1\n",
    "    population = [Agent(n_inputs,n_hidden,n_actions,mutate_rate,multiplier) for i in list(range(pop_size))]\n",
    "    scores = [run_trial(env,agent) for agent in population]\n",
    "    best = [deepcopy(population[np.argmax(scores)])]\n",
    "    for generation in list(range(n_generations)):\n",
    "        population,scores = next_generation(env,population, scores,softmax_temp)\n",
    "        best.append(deepcopy(population[np.argmax(scores)]))\n",
    "        print(\"Generation:\",generation,\"Score:\",np.max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Record every agent\n",
    "    env = gym.wrappers.Monitor(env,'/video/',force=True,video_callable=lambda episode_id: episode_id%3==0)   \n",
    "    for agent in best:\n",
    "        run_trial(env,agent)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
